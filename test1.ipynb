{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "import numpy as np\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "tr = sc.textFile(\"datasets/medium.txt\").zipWithUniqueId()\n",
    "k = sc.broadcast(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart = tr.cartesian(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distances (dt):\n",
    "    idts = dt[0][1]\n",
    "    test = dt[0][0].split(\",\")\n",
    "    ts = list(map(float, test[0:11]))\n",
    "    clts = int(test[11])\n",
    "    idtr = dt[1][1]\n",
    "    train = dt[1][0].split(\",\")\n",
    "    tr = list(map(float, train[0:11]))\n",
    "    cltr = int(train[11])\n",
    "    \n",
    "    dist = sum((p-q)**2 for p, q in zip(ts, tr)) ** .5\n",
    "    \n",
    "    if idts == idtr:\n",
    "        dist = float(\"inf\")\n",
    "    \n",
    "    return (idts,(dist,cltr,clts))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dist = cart.map(distances)\n",
    "dist.saveAsTextFile('dist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_klist(value):\n",
    "    x = [(float('inf'),0)]*k.value\n",
    "    x[0] = value\n",
    "    return x\n",
    "\n",
    "def merge_klist(x, value):\n",
    "    for i in range(len(x)):\n",
    "        if value[0]<x[i][0]:\n",
    "            for j in range(len(x)-1,i,-1):\n",
    "                x[j]=x[j-1]\n",
    "            x[i]=value\n",
    "            break\n",
    "    return x\n",
    "\n",
    "def merge_combiners(x,y):\n",
    "    l = 0\n",
    "    for i in range(len(x)):\n",
    "        if y[l][0]<x[i][0]:\n",
    "            for j in range(len(x)-1,i,-1):\n",
    "                x[j]=x[j-1]\n",
    "            x[i]=y[l]\n",
    "            l+=1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_klist(value):\n",
    "    x = [(float('inf'),0)]*k.value\n",
    "    x[0] = value\n",
    "    return x\n",
    "\n",
    "def merge_klist(x, value):\n",
    "    for i in range(len(x)):\n",
    "        if value[0]<x[i][0]:\n",
    "            x.insert(i,value)\n",
    "            x.pop()\n",
    "            break\n",
    "    return x\n",
    "\n",
    "def merge_combiners(x,y):\n",
    "    l = 0\n",
    "    for i in range(len(x)):\n",
    "        if y[l][0]<x[i][0]:\n",
    "            x.insert(i,y[l])\n",
    "            x.pop()\n",
    "            l+=1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_vals = dist.combineByKey(create_klist, merge_klist, merge_combiners)\n",
    "k_vals.saveAsTextFile('k_vals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guess_class(dt):\n",
    "    rclass = dt[1][0][2]\n",
    "    freq = 0\n",
    "    predict = 0\n",
    "    for i in range(len(dt[1])):\n",
    "        tfreq = 1\n",
    "        tpredict = dt[1][i][1]\n",
    "        for j in range(i+1,len(dt[1])):\n",
    "            if tpredict == dt[1][j][1]:\n",
    "                tfreq +=1\n",
    "        if tfreq > freq:\n",
    "            predict = tpredict\n",
    "            freq = tfreq\n",
    "            \n",
    "    \n",
    "    return (rclass,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess_class = k_vals.map(guess_class)\n",
    "guess_class.saveAsTextFile('guess_class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct(dt):\n",
    "    if dt[0]==dt[1]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = guess_class.map(correct)\n",
    "accuracy = correct.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2521"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accum = sc.accumulator(0)\n",
    "correct.foreach(lambda x: accum.add(x))\n",
    "accum.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.514699877501021"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time to run is: 128.87910389900208\n",
      "0.6161698652511226\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "def distances (dt):\n",
    "    idts = dt[0][1]\n",
    "    test = dt[0][0].split(\",\")\n",
    "    ts = list(map(float, test[0:11]))\n",
    "    clts = int(test[11])\n",
    "    idtr = dt[1][1]\n",
    "    train = dt[1][0].split(\",\")\n",
    "    tr = list(map(float, train[0:11]))\n",
    "    cltr = int(train[11])\n",
    "    \n",
    "    dist = sum((p-q)**2 for p, q in zip(ts, tr)) ** .5\n",
    "    \n",
    "    if idts == idtr:\n",
    "        dist = float(\"inf\")\n",
    "    \n",
    "    return (idts,(dist,cltr,clts))\n",
    "    \n",
    "def create_klist(value):\n",
    "    x = [(float('inf'),0)]*k.value\n",
    "    x[0] = value\n",
    "    return x\n",
    "\n",
    "def merge_klist(x, value):\n",
    "    for i in range(len(x)):\n",
    "        if value[0]<x[i][0]:\n",
    "            x.insert(i,value)\n",
    "            x.pop()\n",
    "            break\n",
    "    return x\n",
    "\n",
    "def merge_combiners(x,y):\n",
    "    l = 0\n",
    "    for i in range(len(x)):\n",
    "        if y[l][0]<x[i][0]:\n",
    "            x.insert(i,y[l])\n",
    "            x.pop()\n",
    "            l+=1\n",
    "    return x\n",
    "\n",
    "def guess_class(dt):\n",
    "    rclass = dt[1][0][2]\n",
    "    freq = 0\n",
    "    predict = 0\n",
    "    for i in range(len(dt[1])):\n",
    "        tfreq = 1\n",
    "        tpredict = dt[1][i][1]\n",
    "        for j in range(i+1,len(dt[1])):\n",
    "            if tpredict == dt[1][j][1]:\n",
    "                tfreq +=1\n",
    "        if tfreq > freq:\n",
    "            predict = tpredict\n",
    "            freq = tfreq\n",
    "            \n",
    "    \n",
    "    return (rclass,predict)\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "tr = sc.textFile(\"datasets/medium.txt\").zipWithUniqueId()\n",
    "k = sc.broadcast(1)\n",
    "\n",
    "cart = tr.cartesian(tr)\n",
    "dist = cart.map(distances)\n",
    "k_vals = dist.combineByKey(create_klist, merge_klist, merge_combiners)\n",
    "guess_class = k_vals.map(guess_class)\n",
    "\n",
    "\n",
    "\n",
    "def correct(dt):\n",
    "    if dt[0]==dt[1]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "correct = guess_class.map(correct)\n",
    "accuracy = correct.mean()\n",
    "end = time.time()\n",
    "print('The time to run is:', end - start)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time to run is: 114.2023377418518\n",
      "0.6161698652511226\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "def distances (dt):\n",
    "    idts = dt[0][1]\n",
    "    test = dt[0][0].split(\",\")\n",
    "    ts = list(map(float, test[0:11]))\n",
    "    clts = int(test[11])\n",
    "    idtr = dt[1][1]\n",
    "    train = dt[1][0].split(\",\")\n",
    "    tr = list(map(float, train[0:11]))\n",
    "    cltr = int(train[11])\n",
    "    \n",
    "    dist = sum((p-q)**2 for p, q in zip(ts, tr)) ** .5\n",
    "    \n",
    "    if idts == idtr:\n",
    "        dist = float(\"inf\")\n",
    "    \n",
    "    return (idts,(dist,cltr,clts))\n",
    "    \n",
    "def create_klist(value):\n",
    "    x = [(float('inf'),0)]*k.value\n",
    "    x[0] = value\n",
    "    return x\n",
    "\n",
    "def merge_klist(x, value):\n",
    "    for i in range(len(x)):\n",
    "        if value[0]<x[i][0]:\n",
    "            for j in range(len(x)-1,i,-1):\n",
    "                x[j]=x[j-1]\n",
    "            x[i]=value\n",
    "            break\n",
    "    return x\n",
    "\n",
    "def merge_combiners(x,y):\n",
    "    l = 0\n",
    "    for i in range(len(x)):\n",
    "        if y[l][0]<x[i][0]:\n",
    "            for j in range(len(x)-1,i,-1):\n",
    "                x[j]=x[j-1]\n",
    "            x[i]=y[l]\n",
    "            l+=1\n",
    "    return x\n",
    "\n",
    "def guess_class(dt):\n",
    "    rclass = dt[1][0][2]\n",
    "    freq = 0\n",
    "    predict = 0\n",
    "    for i in range(len(dt[1])):\n",
    "        tfreq = 1\n",
    "        tpredict = dt[1][i][1]\n",
    "        for j in range(i+1,len(dt[1])):\n",
    "            if tpredict == dt[1][j][1]:\n",
    "                tfreq +=1\n",
    "        if tfreq > freq:\n",
    "            predict = tpredict\n",
    "            freq = tfreq\n",
    "            \n",
    "    \n",
    "    return (rclass,predict)\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "tr = sc.textFile(\"datasets/medium.txt\").zipWithUniqueId()\n",
    "k = sc.broadcast(1)\n",
    "\n",
    "cart = tr.cartesian(tr)\n",
    "dist = cart.map(distances)\n",
    "k_vals = dist.combineByKey(create_klist, merge_klist, merge_combiners)\n",
    "guess_class = k_vals.map(guess_class)\n",
    "\n",
    "\n",
    "\n",
    "def correct(dt):\n",
    "    if dt[0]==dt[1]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "correct = guess_class.map(correct)\n",
    "accuracy = correct.mean()\n",
    "end = time.time()\n",
    "print('The time to run is:', end - start)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
